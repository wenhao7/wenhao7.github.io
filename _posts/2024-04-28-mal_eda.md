---
layout: post
title:  "Anime Datasets EDA"
date:   2024-04-28 19:57:09 +0800
category: [data_analysis, visualization, misc]
tag: [numpy, pandas, seaborn, statistics, statsmodels, matplotlib]
summary: "In this notebook we will explore the datasets scraped by our webscraping scripts. Exploration in this notebook will be guided by some key questions within each section."
image: /images/banners/mal_eda.png
---

***
## Contents
1. [Introduction](#1)
2. [Anime Info Dataset EDA](#2)
3. [Anime Reviews Dataset EDA](#3)
4. [User Ratings Dataset EDA](#4)
5. [Conclusion](#5)

<a id='1'></a>
## 1. Introduction
In this notebook we will explore the datasets scraped by our [webscraping scripts](https://github.com/wenhao7/MAL_scrape). A previous notebook going through these scripts can be found [here](https://wenhao7.github.io/data_wrangling/misc/2024/04/12/mal_scrape_part1.html). Exploration in this notebook will be guided by some key questions within each section.


```python
import pandas as pd
import numpy as np
from ast import literal_eval
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import statsmodels as sm
warnings.filterwarnings('ignore')
```

<a id='2'></a>
## 2. Anime Info Dataset EDA
In this section we will look at the dataset containing information for the 13,300 titles scraped, guided by the following questions:
 1. [How many episodes does a title usually run for?](#2.1)
 2. [Longest running titles?](#2.2)
 3. [Best performing studios?](#2.3)
 4. [Number of titles released over the years](#2.4)
 5. [How are titles scored?](#2.5)
 
First we will look at some general information from this dataset.


```python
cleaned_df = pd.read_csv('cleaned_anime_info.csv')
cleaned_df['Aired_Start'] = pd.to_datetime(cleaned_df['Aired_Start'], errors='coerce')
cleaned_df['Aired_End'] = pd.to_datetime(cleaned_df['Aired_End'], errors='coerce')
cleaned_df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MAL_Id</th>
      <th>Name</th>
      <th>Type</th>
      <th>Episodes</th>
      <th>Status</th>
      <th>Producers</th>
      <th>Licensors</th>
      <th>Studios</th>
      <th>Source</th>
      <th>Genres</th>
      <th>...</th>
      <th>Score-2</th>
      <th>Score-1</th>
      <th>Synopsis</th>
      <th>Voice_Actors</th>
      <th>Recommended_Ids</th>
      <th>Recommended_Counts</th>
      <th>Aired_Start</th>
      <th>Aired_End</th>
      <th>Premiered_Season</th>
      <th>Rank</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>52991</td>
      <td>Sousou no Frieren</td>
      <td>TV</td>
      <td>28.0</td>
      <td>Finished Airing</td>
      <td>['Aniplex', 'Dentsu', 'Shogakukan-Shueisha Pro...</td>
      <td>['None found', 'add some']</td>
      <td>['Madhouse']</td>
      <td>Manga</td>
      <td>['Adventure', 'Drama', 'Fantasy', 'Shounen']</td>
      <td>...</td>
      <td>402</td>
      <td>4100</td>
      <td>During their decade-long quest to defeat the D...</td>
      <td>['Tanezaki, Atsumi', 'Ichinose, Kana', 'Kobaya...</td>
      <td>['33352', '41025', '35851', '486', '457', '296...</td>
      <td>['14', '11', '8', '5', '5', '4', '4', '3', '2'...</td>
      <td>2023-09-29</td>
      <td>2024-03-22</td>
      <td>4.0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5114</td>
      <td>Fullmetal Alchemist: Brotherhood</td>
      <td>TV</td>
      <td>64.0</td>
      <td>Finished Airing</td>
      <td>['Aniplex', 'Square Enix', 'Mainichi Broadcast...</td>
      <td>['Funimation', 'Aniplex of America']</td>
      <td>['Bones']</td>
      <td>Manga</td>
      <td>['Action', 'Adventure', 'Drama', 'Fantasy', 'M...</td>
      <td>...</td>
      <td>3460</td>
      <td>50602</td>
      <td>After a horrific alchemy experiment goes wrong...</td>
      <td>['Park, Romi', 'Kugimiya, Rie', 'Miki, Shinich...</td>
      <td>['11061', '16498', '1482', '38000', '9919', '1...</td>
      <td>['74', '44', '21', '17', '16', '14', '14', '9'...</td>
      <td>2009-04-05</td>
      <td>2010-07-04</td>
      <td>2.0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>9253</td>
      <td>Steins;Gate</td>
      <td>TV</td>
      <td>24.0</td>
      <td>Finished Airing</td>
      <td>['Frontier Works', 'Media Factory', 'Kadokawa ...</td>
      <td>['Funimation']</td>
      <td>['White Fox']</td>
      <td>Visual novel</td>
      <td>['Drama', 'Sci-Fi', 'Suspense', 'Psychological...</td>
      <td>...</td>
      <td>2868</td>
      <td>10054</td>
      <td>Eccentric scientist Rintarou Okabe has a never...</td>
      <td>['Miyano, Mamoru', 'Imai, Asami', 'Hanazawa, K...</td>
      <td>['31043', '31240', '9756', '10620', '2236', '4...</td>
      <td>['132', '130', '48', '26', '24', '19', '19', '...</td>
      <td>2011-04-06</td>
      <td>2011-09-14</td>
      <td>2.0</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>28977</td>
      <td>Gintama°</td>
      <td>TV</td>
      <td>51.0</td>
      <td>Finished Airing</td>
      <td>['TV Tokyo', 'Aniplex', 'Dentsu']</td>
      <td>['Funimation', 'Crunchyroll']</td>
      <td>['Bandai Namco Pictures']</td>
      <td>Manga</td>
      <td>['Action', 'Comedy', 'Sci-Fi', 'Gag Humor', 'H...</td>
      <td>...</td>
      <td>1477</td>
      <td>8616</td>
      <td>Gintoki, Shinpachi, and Kagura return as the f...</td>
      <td>['Sugita, Tomokazu', 'Kugimiya, Rie', 'Sakaguc...</td>
      <td>['9863', '30276', '33255', '37105', '6347', '3...</td>
      <td>['3', '2', '1', '1', '1', '1', '1', '1', '1', ...</td>
      <td>2015-04-08</td>
      <td>2016-03-30</td>
      <td>2.0</td>
      <td>4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>38524</td>
      <td>Shingeki no Kyojin Season 3 Part 2</td>
      <td>TV</td>
      <td>10.0</td>
      <td>Finished Airing</td>
      <td>['Production I.G', 'Dentsu', 'Mainichi Broadca...</td>
      <td>['Funimation']</td>
      <td>['Wit Studio']</td>
      <td>Manga</td>
      <td>['Action', 'Drama', 'Suspense', 'Gore', 'Milit...</td>
      <td>...</td>
      <td>1308</td>
      <td>12803</td>
      <td>Seeking to restore humanity's diminishing hope...</td>
      <td>['Kamiya, Hiroshi', 'Kaji, Yuuki', 'Ishikawa, ...</td>
      <td>['28623', '37521', '25781', '2904', '36649', '...</td>
      <td>['1', '1', '1', '1', '1', '1', '1', '1', '1', ...</td>
      <td>2019-04-29</td>
      <td>2019-07-01</td>
      <td>2.0</td>
      <td>5</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 40 columns</p>
</div>




```python
cleaned_df.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 13300 entries, 0 to 13299
    Data columns (total 40 columns):
     #   Column              Non-Null Count  Dtype         
    ---  ------              --------------  -----         
     0   MAL_Id              13300 non-null  int64         
     1   Name                13300 non-null  object        
     2   Type                13300 non-null  object        
     3   Episodes            13245 non-null  float64       
     4   Status              13300 non-null  object        
     5   Producers           13300 non-null  object        
     6   Licensors           13300 non-null  object        
     7   Studios             13300 non-null  object        
     8   Source              13300 non-null  object        
     9   Genres              13300 non-null  object        
     10  Duration            13300 non-null  object        
     11  Rating              13211 non-null  object        
     12  Score               13300 non-null  float64       
     13  Popularity          13300 non-null  int64         
     14  Members             13300 non-null  int64         
     15  Favorites           13300 non-null  int64         
     16  Watching            13300 non-null  int64         
     17  Completed           13300 non-null  int64         
     18  On-Hold             13300 non-null  int64         
     19  Dropped             13300 non-null  int64         
     20  Plan to Watch       13300 non-null  int64         
     21  Total               13300 non-null  int64         
     22  Score-10            13300 non-null  int64         
     23  Score-9             13300 non-null  int64         
     24  Score-8             13300 non-null  int64         
     25  Score-7             13300 non-null  int64         
     26  Score-6             13300 non-null  int64         
     27  Score-5             13300 non-null  int64         
     28  Score-4             13300 non-null  int64         
     29  Score-3             13300 non-null  int64         
     30  Score-2             13300 non-null  int64         
     31  Score-1             13300 non-null  int64         
     32  Synopsis            13300 non-null  object        
     33  Voice_Actors        13300 non-null  object        
     34  Recommended_Ids     13300 non-null  object        
     35  Recommended_Counts  13300 non-null  object        
     36  Aired_Start         13289 non-null  datetime64[ns]
     37  Aired_End           7148 non-null   datetime64[ns]
     38  Premiered_Season    13289 non-null  float64       
     39  Rank                13300 non-null  int64         
    dtypes: datetime64[ns](2), float64(3), int64(21), object(14)
    memory usage: 4.1+ MB
    

Here we notice some missing values from 'Episodes','Rating','Aired_Start','Aired_End','Premiered_Season'.


```python
cleaned_df.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MAL_Id</th>
      <th>Episodes</th>
      <th>Score</th>
      <th>Popularity</th>
      <th>Members</th>
      <th>Favorites</th>
      <th>Watching</th>
      <th>Completed</th>
      <th>On-Hold</th>
      <th>Dropped</th>
      <th>...</th>
      <th>Score-6</th>
      <th>Score-5</th>
      <th>Score-4</th>
      <th>Score-3</th>
      <th>Score-2</th>
      <th>Score-1</th>
      <th>Aired_Start</th>
      <th>Aired_End</th>
      <th>Premiered_Season</th>
      <th>Rank</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>13300.000000</td>
      <td>13245.000000</td>
      <td>13300.000000</td>
      <td>13300.000000</td>
      <td>1.330000e+04</td>
      <td>13300.000000</td>
      <td>1.330000e+04</td>
      <td>1.330000e+04</td>
      <td>13300.000000</td>
      <td>13300.000000</td>
      <td>...</td>
      <td>13300.000000</td>
      <td>13300.000000</td>
      <td>13300.000000</td>
      <td>13300.000000</td>
      <td>13300.000000</td>
      <td>13300.000000</td>
      <td>13289</td>
      <td>7148</td>
      <td>13289.000000</td>
      <td>13300.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>22248.567669</td>
      <td>13.740506</td>
      <td>6.456092</td>
      <td>7936.567744</td>
      <td>7.285031e+04</td>
      <td>854.796466</td>
      <td>4.751001e+03</td>
      <td>4.703889e+04</td>
      <td>1878.256692</td>
      <td>2406.951579</td>
      <td>...</td>
      <td>3976.735940</td>
      <td>1944.259549</td>
      <td>868.131654</td>
      <td>396.392707</td>
      <td>229.843383</td>
      <td>252.029925</td>
      <td>2007-03-30 05:47:17.685303552</td>
      <td>2010-01-27 17:09:50.263010816</td>
      <td>2.432764</td>
      <td>6650.500000</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.869653</td>
      <td>1.000000</td>
      <td>1.240000e+02</td>
      <td>0.000000</td>
      <td>4.000000e+00</td>
      <td>0.000000e+00</td>
      <td>0.000000</td>
      <td>7.000000</td>
      <td>...</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1917-01-01 00:00:00</td>
      <td>1962-02-25 00:00:00</td>
      <td>1.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>5004.250000</td>
      <td>1.000000</td>
      <td>5.827480</td>
      <td>3411.750000</td>
      <td>1.418000e+03</td>
      <td>1.000000</td>
      <td>7.000000e+01</td>
      <td>5.840000e+02</td>
      <td>35.000000</td>
      <td>89.000000</td>
      <td>...</td>
      <td>81.000000</td>
      <td>71.000000</td>
      <td>32.000000</td>
      <td>18.000000</td>
      <td>11.000000</td>
      <td>20.000000</td>
      <td>2001-05-10 00:00:00</td>
      <td>2004-06-21 12:00:00</td>
      <td>1.000000</td>
      <td>3325.750000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>20850.000000</td>
      <td>3.000000</td>
      <td>6.548627</td>
      <td>7537.500000</td>
      <td>6.592000e+03</td>
      <td>10.000000</td>
      <td>2.770000e+02</td>
      <td>3.199000e+03</td>
      <td>144.000000</td>
      <td>183.000000</td>
      <td>...</td>
      <td>461.000000</td>
      <td>275.000000</td>
      <td>109.000000</td>
      <td>55.000000</td>
      <td>32.000000</td>
      <td>41.000000</td>
      <td>2011-07-30 00:00:00</td>
      <td>2013-06-21 12:00:00</td>
      <td>2.000000</td>
      <td>6650.500000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>37095.250000</td>
      <td>13.000000</td>
      <td>7.205349</td>
      <td>12211.000000</td>
      <td>4.213000e+04</td>
      <td>100.000000</td>
      <td>1.722000e+03</td>
      <td>2.288675e+04</td>
      <td>839.000000</td>
      <td>892.250000</td>
      <td>...</td>
      <td>2709.000000</td>
      <td>1364.250000</td>
      <td>528.250000</td>
      <td>240.000000</td>
      <td>133.000000</td>
      <td>140.000000</td>
      <td>2017-10-03 00:00:00</td>
      <td>2018-12-07 18:00:00</td>
      <td>3.000000</td>
      <td>9975.250000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>58592.000000</td>
      <td>3057.000000</td>
      <td>9.276142</td>
      <td>21779.000000</td>
      <td>3.928648e+06</td>
      <td>225215.000000</td>
      <td>1.658868e+06</td>
      <td>3.445820e+06</td>
      <td>277825.000000</td>
      <td>218766.000000</td>
      <td>...</td>
      <td>269758.000000</td>
      <td>173778.000000</td>
      <td>110044.000000</td>
      <td>58187.000000</td>
      <td>33200.000000</td>
      <td>50602.000000</td>
      <td>2024-04-08 00:00:00</td>
      <td>2024-04-27 00:00:00</td>
      <td>4.000000</td>
      <td>13300.000000</td>
    </tr>
    <tr>
      <th>std</th>
      <td>17416.784305</td>
      <td>52.926585</td>
      <td>1.027267</td>
      <td>5098.692655</td>
      <td>2.210112e+05</td>
      <td>6223.221896</td>
      <td>2.238497e+04</td>
      <td>1.636013e+05</td>
      <td>7004.696705</td>
      <td>7893.897702</td>
      <td>...</td>
      <td>11176.487076</td>
      <td>5544.392422</td>
      <td>2974.903574</td>
      <td>1483.749934</td>
      <td>949.186809</td>
      <td>1180.692242</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.124617</td>
      <td>3839.523625</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 26 columns</p>
</div>



<a id='2.1'></a>
### 2.1 How many episodes does a title usually run for?


```python
sns.countplot(data=cleaned_df, x='Type')
```




    <Axes: xlabel='Type', ylabel='count'>




    
![png](/images/mal_eda/output_8_1.png)
    



```python
cleaned_df[(cleaned_df.Type=='TV')]['Episodes'].describe()
```




    count    4715.000000
    mean       31.006575
    std        84.461690
    min         2.000000
    25%        12.000000
    50%        13.000000
    75%        26.000000
    max      3057.000000
    Name: Episodes, dtype: float64




```python
cleaned_df[(cleaned_df.Type!='TV')]['Episodes'].describe()
```




    count    8530.000000
    mean        4.196600
    std        12.289696
    min         1.000000
    25%         1.000000
    50%         1.000000
    75%         3.000000
    max       496.000000
    Name: Episodes, dtype: float64



Within "Type" TV series is the largest category, for the other categories we see that a majority of them are a one time thing with a single episode so we will be focusing on the TV category for this section


```python
sns.histplot(data=cleaned_df[(cleaned_df.Type=='TV')&(cleaned_df.Episodes<=30)], x='Episodes', bins=30, binrange=(0,30))
plt.title('Distribution of No. of Episodes (TV Titles <= 30 Episodes)')
```




    Text(0.5, 1.0, 'Distribution of No. of Episodes (TV Titles <= 30 Episodes)')




    
![png](/images/mal_eda/output_12_1.png)
    


For TV series with <= 30 Episodes, the most popular run length is 12 episodes long, followed by 13 and 26 episode lengths.


```python
sns.histplot(data=cleaned_df[(cleaned_df.Type=='TV')&(cleaned_df.Episodes>30)&(cleaned_df.Episodes<=250)], x='Episodes', bins=22, binrange=(30,250))
plt.title('Distribution of No. of Episodes (TV Titles 30 < Episodes <= 250)')
```




    Text(0.5, 1.0, 'Distribution of No. of Episodes (TV Titles 30 < Episodes <= 250)')




    
![png](/images/mal_eda/output_14_1.png)
    


Looking at titles with 30 < Eipsodes <= 250, most fall within the 50 to 60 episodes range, followed by 40 to 50 and 30 to 40 episodes.


```python
sns.histplot(data=cleaned_df[(cleaned_df.Type=='TV')&(cleaned_df.Episodes>250)], x='Episodes', bins=26, binrange=(250,3500))
plt.title('Distribution of No. of Episodes (TV Titles 250 > Episodes)')
```




    Text(0.5, 1.0, 'Distribution of No. of Episodes (TV Titles 250 > Episodes)')




    
![png](/images/mal_eda/output_16_1.png)
    


Looking at the outlier long running titles we see that most fall between 250 to 500 episodes, with an outlier running for more than 3000 episodes!


```python
cleaned_df[cleaned_df.Episodes > 1000][['MAL_Id','Name','Episodes','Status','Popularity','Score','Rank','Aired_Start','Aired_End']]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MAL_Id</th>
      <th>Name</th>
      <th>Episodes</th>
      <th>Status</th>
      <th>Popularity</th>
      <th>Score</th>
      <th>Rank</th>
      <th>Aired_Start</th>
      <th>Aired_End</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>904</th>
      <td>2471</td>
      <td>Doraemon (1979)</td>
      <td>1787.0</td>
      <td>Finished Airing</td>
      <td>2737</td>
      <td>7.765135</td>
      <td>905</td>
      <td>1979-04-02</td>
      <td>2005-03-18</td>
    </tr>
    <tr>
      <th>6897</th>
      <td>6277</td>
      <td>Manga Nippon Mukashibanashi (1976)</td>
      <td>1471.0</td>
      <td>Finished Airing</td>
      <td>11722</td>
      <td>6.415709</td>
      <td>6898</td>
      <td>1976-01-07</td>
      <td>1994-09-03</td>
    </tr>
    <tr>
      <th>9028</th>
      <td>9947</td>
      <td>Lan Mao</td>
      <td>3057.0</td>
      <td>Finished Airing</td>
      <td>13932</td>
      <td>5.680556</td>
      <td>9029</td>
      <td>1999-10-08</td>
      <td>2001-08-01</td>
    </tr>
    <tr>
      <th>10202</th>
      <td>8213</td>
      <td>Hokahoka Kazoku</td>
      <td>1428.0</td>
      <td>Finished Airing</td>
      <td>13747</td>
      <td>5.657343</td>
      <td>10203</td>
      <td>1976-10-01</td>
      <td>1982-03-31</td>
    </tr>
    <tr>
      <th>10271</th>
      <td>32448</td>
      <td>Kirin Ashita no Calendar</td>
      <td>1306.0</td>
      <td>Finished Airing</td>
      <td>15099</td>
      <td>5.510000</td>
      <td>10272</td>
      <td>1980-01-01</td>
      <td>1984-10-06</td>
    </tr>
    <tr>
      <th>10709</th>
      <td>22221</td>
      <td>Monoshiri Daigaku: Ashita no Calendar</td>
      <td>1274.0</td>
      <td>Finished Airing</td>
      <td>14150</td>
      <td>5.542986</td>
      <td>10710</td>
      <td>1966-07-01</td>
      <td>1970-08-02</td>
    </tr>
    <tr>
      <th>11038</th>
      <td>10241</td>
      <td>Sekai Monoshiri Ryoko</td>
      <td>1006.0</td>
      <td>Finished Airing</td>
      <td>14208</td>
      <td>5.642553</td>
      <td>11039</td>
      <td>1971-10-01</td>
      <td>1974-12-31</td>
    </tr>
    <tr>
      <th>11256</th>
      <td>23349</td>
      <td>Kirin Monoshiri Yakata</td>
      <td>1565.0</td>
      <td>Finished Airing</td>
      <td>14288</td>
      <td>5.335740</td>
      <td>11257</td>
      <td>1975-01-01</td>
      <td>1979-12-31</td>
    </tr>
    <tr>
      <th>11641</th>
      <td>12393</td>
      <td>Oyako Club</td>
      <td>1818.0</td>
      <td>Finished Airing</td>
      <td>12922</td>
      <td>5.518605</td>
      <td>11642</td>
      <td>1994-10-03</td>
      <td>2013-03-30</td>
    </tr>
  </tbody>
</table>
</div>



Above are the outlier titles with the highest number of episodes! Interestingly, except for Doraemon it seems like none of the titles are particularly highly rated or popular.

<a id='2.2'></a>
### 2.2 Longest running titles?


```python
cleaned_df.Status.value_counts()
```




    Status
    Finished Airing     13197
    Currently Airing      103
    Name: count, dtype: int64




```python
currently_airing = cleaned_df[cleaned_df.Status=='Currently Airing']
```


```python
sns.histplot(currently_airing, x='Aired_Start')
plt.title("Currently Airing Titles' Premier Years")
```




    Text(0.5, 1.0, "Currently Airing Titles' Premier Years")




    
![png](/images/mal_eda/output_23_1.png)
    


Looking at titles that are still running, we see that the majority of them premiered in the 2020s as expected. The oldest running title appears to be from around 1970, more than 50 years ago!


```python
currently_airing[currently_airing['Aired_Start'].dt.year < 2000][['MAL_Id','Name','Episodes','Status','Score','Popularity','Rank','Aired_Start']]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MAL_Id</th>
      <th>Name</th>
      <th>Episodes</th>
      <th>Status</th>
      <th>Score</th>
      <th>Popularity</th>
      <th>Rank</th>
      <th>Aired_Start</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>51</th>
      <td>21</td>
      <td>One Piece</td>
      <td>NaN</td>
      <td>Currently Airing</td>
      <td>8.741164</td>
      <td>19</td>
      <td>52</td>
      <td>1999-10-20</td>
    </tr>
    <tr>
      <th>405</th>
      <td>235</td>
      <td>Meitantei Conan</td>
      <td>NaN</td>
      <td>Currently Airing</td>
      <td>8.196769</td>
      <td>675</td>
      <td>406</td>
      <td>1996-01-08</td>
    </tr>
    <tr>
      <th>997</th>
      <td>966</td>
      <td>Crayon Shin-chan</td>
      <td>NaN</td>
      <td>Currently Airing</td>
      <td>7.840472</td>
      <td>2313</td>
      <td>998</td>
      <td>1992-04-13</td>
    </tr>
    <tr>
      <th>2602</th>
      <td>6149</td>
      <td>Chibi Maruko-chan (1995)</td>
      <td>NaN</td>
      <td>Currently Airing</td>
      <td>7.409741</td>
      <td>7834</td>
      <td>2603</td>
      <td>1995-01-08</td>
    </tr>
    <tr>
      <th>3751</th>
      <td>1199</td>
      <td>Nintama Rantarou</td>
      <td>NaN</td>
      <td>Currently Airing</td>
      <td>7.207432</td>
      <td>7119</td>
      <td>3752</td>
      <td>1993-04-10</td>
    </tr>
    <tr>
      <th>5304</th>
      <td>1960</td>
      <td>Sore Ike! Anpanman</td>
      <td>NaN</td>
      <td>Currently Airing</td>
      <td>6.892672</td>
      <td>9096</td>
      <td>5305</td>
      <td>1988-10-03</td>
    </tr>
    <tr>
      <th>7489</th>
      <td>4459</td>
      <td>Ojarumaru</td>
      <td>NaN</td>
      <td>Currently Airing</td>
      <td>6.338290</td>
      <td>11094</td>
      <td>7490</td>
      <td>1998-10-05</td>
    </tr>
    <tr>
      <th>8878</th>
      <td>2406</td>
      <td>Sazae-san</td>
      <td>NaN</td>
      <td>Currently Airing</td>
      <td>6.185860</td>
      <td>6857</td>
      <td>8879</td>
      <td>1969-10-05</td>
    </tr>
  </tbody>
</table>
</div>



Above are titles that starting airing before 2000 and are still airing today, It appears that for these titles the Episodes field is empty as there is no known end date/episode. Compared to the previous section where we looked at aired titles with the highest number of episodes, these titles are more popular and higher rated in general, with very recognizable names like One Piece, Detective Conan, and Crayon Shin-chan within the list.


```python
cleaned_df.iloc[8878]
```




    MAL_Id                                                             2406
    Name                                                          Sazae-san
    Type                                                                 TV
    Episodes                                                            NaN
    Status                                                 Currently Airing
    Producers                                                   ['Fuji TV']
    Licensors                                    ['None found', 'add some']
    Studios                                                       ['Eiken']
    Source                                                     4-koma manga
    Genres                                      ['Comedy', 'Slice of Life']
    Duration                                                        24 min.
    Rating                                                     G - All Ages
    Score                                                           6.18586
    Popularity                                                         6857
    Members                                                            8369
    Favorites                                                            37
    Watching                                                           2171
    Completed                                                             1
    On-Hold                                                             741
    Dropped                                                            1826
    Plan to Watch                                                      3630
    Total                                                              8369
    Score-10                                                            248
    Score-9                                                              97
    Score-8                                                             180
    Score-7                                                             354
    Score-6                                                             353
    Score-5                                                             266
    Score-4                                                             101
    Score-3                                                              55
    Score-2                                                              48
    Score-1                                                             165
    Synopsis              The main character is a mother named Sazae-san...
    Voice_Actors          ['Katou, Midori', 'Nagai, Ichiro', 'Sasuga, Ta...
    Recommended_Ids                                 ['951', '6149', '6625']
    Recommended_Counts                                      ['1', '1', '1']
    Aired_Start                                         1969-10-05 00:00:00
    Aired_End                                                           NaT
    Premiered_Season                                                    4.0
    Rank                                                               8879
    Name: 8878, dtype: object



Looking at the oldest currently airing title named Sazae-san, apparently it has aired more than 8000 episodes thus far! This is more episodes than the highest number we have seen in this dataset (3057 episodes), however as the title is still airing with no planned ending, the final episode count is listed as Unknown on the website.

<a id='2.3'></a>
### 2.3 Best performing studios?


```python
studios = cleaned_df.copy()
studios.Studios
```




    0                           ['Madhouse']
    1                              ['Bones']
    2                          ['White Fox']
    3              ['Bandai Namco Pictures']
    4                         ['Wit Studio']
                          ...               
    13295       ['Toei Animation', 'Gallop']
    13296    ['Production I.G', 'Signal.MD']
    13297                            ['OLM']
    13298                 ['Toei Animation']
    13299         ['None found', 'add some']
    Name: Studios, Length: 13300, dtype: object




```python
# evaluate the Studios column as a list of strings
studios['Studios'] = studios['Studios'].apply(literal_eval)
```


```python
# explode the studios column to make multiple entries for titles with multiple studios, one try for each studio
studios = studios.explode('Studios')
```


```python
studios.Studios.value_counts()
```




    Studios
    None found                           2219
    add some                             2219
    Toei Animation                        735
    Sunrise                               509
    J.C.Staff                             386
                                         ... 
    uzupiyo Animation & Digital Works       1
    VROOOOM                                 1
    Mook DLE                                1
    Studio Korumi                           1
    Anime Tokyo                             1
    Name: count, Length: 812, dtype: int64



We see that Toei Animation has worked on the highest number of titles, 2219 titles have missing studios information


```python
studios.Studios.value_counts().describe()
```




    count     812.000000
    mean       20.418719
    std       119.205020
    min         1.000000
    25%         1.000000
    50%         3.000000
    75%         9.000000
    max      2219.000000
    Name: count, dtype: float64




```python
# Remove entries with unknown studios
studios = studios[(~studios.Studios.str.contains('add some|None found'))]
```

#### Distribution of Number of Titles per Studio


```python
num_titles = studios.Studios.value_counts().reset_index()
num_titles.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Studios</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Toei Animation</td>
      <td>735</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Sunrise</td>
      <td>509</td>
    </tr>
    <tr>
      <th>2</th>
      <td>J.C.Staff</td>
      <td>386</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Madhouse</td>
      <td>351</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Production I.G</td>
      <td>317</td>
    </tr>
  </tbody>
</table>
</div>




```python
print("Number of Studios with only 1 title : ", len(num_titles[num_titles['count'] == 1]))
print("Number of Studios with 2~5 titles : ", len(num_titles[(num_titles['count']<=5)&(num_titles['count']>=2)]))
print("Number of Studios with >5 titles : ", len(num_titles[num_titles['count'] >5] ))
```

    Number of Studios with only 1 title :  253
    Number of Studios with 2~5 titles :  285
    Number of Studios with >5 titles :  272
    

More than 2/3 of Studios are attributed to <= 5 titles


```python
ax = sns.histplot(num_titles[num_titles['count'] >5], x='count', bins=50)
ax.set(xlabel='Number of Titles', ylabel='Number of Studios')
plt.title('Distribution of Number of Titles per Studio (with >5 Titles)')
```




    Text(0.5, 1.0, 'Distribution of Number of Titles per Studio (with >5 Titles)')




    
![png](/images/mal_eda/output_40_1.png)
    


Looking at studios with >5 titles, most fall under 100 titles. However some larger/longer standing studios have more than 300 titles attributed to them.

#### Distribution of Average Score per Studio


```python
avg_score = studios.groupby('Studios')['Score'].mean().reset_index()
avg_score
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Studios</th>
      <th>Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>10Gauge</td>
      <td>6.800447</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2:10 AM Animation</td>
      <td>6.439553</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5 Inc.</td>
      <td>5.997731</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7doc</td>
      <td>6.157123</td>
    </tr>
    <tr>
      <th>4</th>
      <td>81 Produce</td>
      <td>5.324742</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>805</th>
      <td>team Yamahitsuji</td>
      <td>7.286680</td>
    </tr>
    <tr>
      <th>806</th>
      <td>teamKG</td>
      <td>6.011747</td>
    </tr>
    <tr>
      <th>807</th>
      <td>ufotable</td>
      <td>7.209364</td>
    </tr>
    <tr>
      <th>808</th>
      <td>uzupiyo Animation &amp; Digital Works</td>
      <td>6.049351</td>
    </tr>
    <tr>
      <th>809</th>
      <td>yell</td>
      <td>4.593171</td>
    </tr>
  </tbody>
</table>
<p>810 rows × 2 columns</p>
</div>




```python
ax = sns.histplot(avg_score, x='Score')
ax.set(xlabel='Average Score')

quantiles = ['25%','50%','75%']
colors = ['red','orange','green']
for i in range(len(quantiles)):
    a = avg_score.describe().transpose()[quantiles[i]]['Score']
    ax.axvline(a, color=colors[i], label=f'Q{i+1} : {a:.2f}')
plt.legend()
plt.title('Distribution of Average Scores of the Studios')
```




    Text(0.5, 1.0, 'Distribution of Average Scores of the Studios')




    
![png](/images/mal_eda/output_43_1.png)
    


Most studios have an average score between 5.80 to 6.82


```python
studios_agg = studios.groupby('Studios')['Score'].agg(['count','mean']).reset_index().sort_values('count', ascending=False)
studios_agg[:10]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Studios</th>
      <th>count</th>
      <th>mean</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>706</th>
      <td>Toei Animation</td>
      <td>735</td>
      <td>6.646888</td>
    </tr>
    <tr>
      <th>668</th>
      <td>Sunrise</td>
      <td>509</td>
      <td>6.857137</td>
    </tr>
    <tr>
      <th>295</th>
      <td>J.C.Staff</td>
      <td>386</td>
      <td>6.805965</td>
    </tr>
    <tr>
      <th>371</th>
      <td>Madhouse</td>
      <td>351</td>
      <td>6.955988</td>
    </tr>
    <tr>
      <th>483</th>
      <td>Production I.G</td>
      <td>317</td>
      <td>7.041709</td>
    </tr>
    <tr>
      <th>678</th>
      <td>TMS Entertainment</td>
      <td>306</td>
      <td>6.945850</td>
    </tr>
    <tr>
      <th>599</th>
      <td>Studio Deen</td>
      <td>291</td>
      <td>6.930208</td>
    </tr>
    <tr>
      <th>467</th>
      <td>Pierrot</td>
      <td>263</td>
      <td>6.790359</td>
    </tr>
    <tr>
      <th>424</th>
      <td>OLM</td>
      <td>261</td>
      <td>6.630814</td>
    </tr>
    <tr>
      <th>6</th>
      <td>A-1 Pictures</td>
      <td>219</td>
      <td>7.158236</td>
    </tr>
  </tbody>
</table>
</div>




```python
print(f"The top 10 studios has worked on {studios_agg[:10]['count'].sum() * 100 / studios_agg['count'].sum():.2f}% of all titles in the dataset")
```

    The top 10 studios has worked on 29.96% of all titles in the dataset
    


```python
fig,ax = plt.subplots(2,1)
sns.barplot(studios_agg[:10], x='Studios', y='count', ax=ax[0])
sns.barplot(studios_agg[:10], x='Studios', y='mean', ax=ax[1])
ax[0].set(ylabel='Number of Titles')
ax[0].get_xaxis().set_visible(False)
ax[0].set_ylim(bottom = studios_agg[:10]['count'].min()-20, top = studios_agg[:10]['count'].max()+20)
ax[1].set(ylabel='Mean Score')
ax[1].set_ylim(bottom = studios_agg[:10]['mean'].min()-0.5, top = studios_agg[:10]['mean'].max()+0.5)
ax[1].set_xticklabels(ax[1].get_xticklabels(), rotation=45, ha='right')

quantiles = ['50%','75%']
colors = ['orange','green']
for i in range(len(quantiles)):
    a = avg_score.describe().transpose()[quantiles[i]]['Score']
    ax[1].axhline(a, color=colors[i], label=f'Q{i+2} : {a:.2f}')
fig.legend(loc='center right')
fig.suptitle('Number of Titles/Mean Scores of the Top 10 Largest Studios')
fig.tight_layout()
fig.show()
```


    
![png](/images/mal_eda/output_47_0.png)
    


All the top studios have average scores better than the median of the industry, a few of them such as Production I.G and A-1 Pictures have average scores better than the 75% percentile of the industry.


```python
studios_agg.sort_values('mean', ascending=False)[:10]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Studios</th>
      <th>count</th>
      <th>mean</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>419</th>
      <td>Nippon Ramayana Film Co.</td>
      <td>1</td>
      <td>8.390935</td>
    </tr>
    <tr>
      <th>733</th>
      <td>TthunDer Animation</td>
      <td>1</td>
      <td>8.326316</td>
    </tr>
    <tr>
      <th>186</th>
      <td>Egg Firm</td>
      <td>4</td>
      <td>8.251246</td>
    </tr>
    <tr>
      <th>306</th>
      <td>K-Factory</td>
      <td>3</td>
      <td>8.187644</td>
    </tr>
    <tr>
      <th>546</th>
      <td>Shenman Entertainment</td>
      <td>3</td>
      <td>8.105867</td>
    </tr>
    <tr>
      <th>584</th>
      <td>Studio Bind</td>
      <td>7</td>
      <td>8.100353</td>
    </tr>
    <tr>
      <th>543</th>
      <td>Sharefun Studio</td>
      <td>4</td>
      <td>8.085452</td>
    </tr>
    <tr>
      <th>651</th>
      <td>Studio Signpost</td>
      <td>5</td>
      <td>7.979743</td>
    </tr>
    <tr>
      <th>13</th>
      <td>AHA Entertainment</td>
      <td>2</td>
      <td>7.956859</td>
    </tr>
    <tr>
      <th>179</th>
      <td>E&amp;H Production</td>
      <td>2</td>
      <td>7.898461</td>
    </tr>
  </tbody>
</table>
</div>




```python
cleaned_df[cleaned_df.Studios.str.contains('Nippon Ramayana Film Co.')]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MAL_Id</th>
      <th>Name</th>
      <th>Type</th>
      <th>Episodes</th>
      <th>Status</th>
      <th>Producers</th>
      <th>Licensors</th>
      <th>Studios</th>
      <th>Source</th>
      <th>Genres</th>
      <th>...</th>
      <th>Score-2</th>
      <th>Score-1</th>
      <th>Synopsis</th>
      <th>Voice_Actors</th>
      <th>Recommended_Ids</th>
      <th>Recommended_Counts</th>
      <th>Aired_Start</th>
      <th>Aired_End</th>
      <th>Premiered_Season</th>
      <th>Rank</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>208</th>
      <td>4921</td>
      <td>Ramayana: The Legend of Prince Rama</td>
      <td>Movie</td>
      <td>1.0</td>
      <td>Finished Airing</td>
      <td>['TEM Co.', 'Ltd.']</td>
      <td>['None found', 'add some']</td>
      <td>['Nippon Ramayana Film Co.']</td>
      <td>Other</td>
      <td>['Adventure']</td>
      <td>...</td>
      <td>21</td>
      <td>69</td>
      <td>Rama, the eldest prince of the Kingdom of Ayod...</td>
      <td>[]</td>
      <td>['40834', '249']</td>
      <td>['1', '1']</td>
      <td>1993-01-15</td>
      <td>NaT</td>
      <td>1.0</td>
      <td>209</td>
    </tr>
  </tbody>
</table>
<p>1 rows × 40 columns</p>
</div>



The studio with the highest mean score has only 1 title as shown above, looks like it was a production studio set up specifically to produce the Ramayana Movie.


```python
studios_agg[studios_agg['count'] >= 10].sort_values('mean', ascending=False)[:10]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Studios</th>
      <th>count</th>
      <th>mean</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>402</th>
      <td>Motion Magic</td>
      <td>12</td>
      <td>7.681899</td>
    </tr>
    <tr>
      <th>49</th>
      <td>Animation Do</td>
      <td>10</td>
      <td>7.649636</td>
    </tr>
    <tr>
      <th>554</th>
      <td>Shuka</td>
      <td>19</td>
      <td>7.604989</td>
    </tr>
    <tr>
      <th>337</th>
      <td>Kyoto Animation</td>
      <td>116</td>
      <td>7.458863</td>
    </tr>
    <tr>
      <th>762</th>
      <td>Wonder Cat Animation</td>
      <td>10</td>
      <td>7.443068</td>
    </tr>
    <tr>
      <th>158</th>
      <td>David Production</td>
      <td>42</td>
      <td>7.377500</td>
    </tr>
    <tr>
      <th>759</th>
      <td>Wit Studio</td>
      <td>68</td>
      <td>7.360997</td>
    </tr>
    <tr>
      <th>682</th>
      <td>TROYCA</td>
      <td>18</td>
      <td>7.357247</td>
    </tr>
    <tr>
      <th>102</th>
      <td>Bones</td>
      <td>146</td>
      <td>7.318575</td>
    </tr>
    <tr>
      <th>127</th>
      <td>CloverWorks</td>
      <td>48</td>
      <td>7.306971</td>
    </tr>
  </tbody>
</table>
</div>



When looking at studios that have worked on >=10 titles, Motion Magic appears to have the highest average score. Some notable studios in the above list are Kyoto ANimation, Wit Studio, and Bones with >50 titles and a high average score suggesting that they have a really good track record of producing well rated titles.

<a id='2.4'></a>
### 2.4 Number of anime titles over the years


```python
sns.histplot(cleaned_df.Aired_Start.dt.year, bins = 50)
```




    <Axes: xlabel='Aired_Start', ylabel='Count'>




    
![png](/images/mal_eda/output_54_1.png)
    


From the above plot we see the number of titles being producted plummeted around 1930s~1960s, possibly due to WW2 and its aftermath. Since then it have been increasing, with a boom since the 2000s. In recent years ~500 titles are released every year compared to the ~100 at year 2000.


```python
cleaned_df.Aired_Start.dt.year.value_counts().iloc[:10]
```




    Aired_Start
    2016.0    617
    2017.0    603
    2018.0    592
    2014.0    583
    2015.0    533
    2021.0    533
    2019.0    510
    2022.0    494
    2012.0    494
    2013.0    487
    Name: count, dtype: int64



The top 10 years with the highest number of titles released are all from between 2010 and now.

<a id='2.5'></a>
### 2.5 How are titles scored?


```python
scores = cleaned_df[cleaned_df.columns[12:32]].copy()
scores['MAL_Id'] = cleaned_df['MAL_Id'].copy()
scores['Name'] = cleaned_df['Name'].copy()
scores['Rank'] = cleaned_df['Rank'].copy()
scores['Popularity'] = cleaned_df['Popularity'].copy()
scores['Episodes'] = cleaned_df['Episodes'].copy()
scores.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Score</th>
      <th>Popularity</th>
      <th>Members</th>
      <th>Favorites</th>
      <th>Watching</th>
      <th>Completed</th>
      <th>On-Hold</th>
      <th>Dropped</th>
      <th>Plan to Watch</th>
      <th>Total</th>
      <th>...</th>
      <th>Score-6</th>
      <th>Score-5</th>
      <th>Score-4</th>
      <th>Score-3</th>
      <th>Score-2</th>
      <th>Score-1</th>
      <th>MAL_Id</th>
      <th>Name</th>
      <th>Rank</th>
      <th>Episodes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>9.276142</td>
      <td>301</td>
      <td>670859</td>
      <td>35435</td>
      <td>256405</td>
      <td>241747</td>
      <td>9365</td>
      <td>6223</td>
      <td>157119</td>
      <td>670859</td>
      <td>...</td>
      <td>3191</td>
      <td>1726</td>
      <td>734</td>
      <td>426</td>
      <td>402</td>
      <td>4100</td>
      <td>52991</td>
      <td>Sousou no Frieren</td>
      <td>1</td>
      <td>28.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>8.941080</td>
      <td>3</td>
      <td>3331144</td>
      <td>225215</td>
      <td>258128</td>
      <td>2407536</td>
      <td>112339</td>
      <td>58874</td>
      <td>494267</td>
      <td>3331144</td>
      <td>...</td>
      <td>31930</td>
      <td>15538</td>
      <td>5656</td>
      <td>2763</td>
      <td>3460</td>
      <td>50602</td>
      <td>5114</td>
      <td>Fullmetal Alchemist: Brotherhood</td>
      <td>2</td>
      <td>64.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>8.962588</td>
      <td>13</td>
      <td>2553356</td>
      <td>189031</td>
      <td>166881</td>
      <td>1601623</td>
      <td>88990</td>
      <td>55596</td>
      <td>640266</td>
      <td>2553356</td>
      <td>...</td>
      <td>31520</td>
      <td>16580</td>
      <td>8023</td>
      <td>3740</td>
      <td>2868</td>
      <td>10054</td>
      <td>9253</td>
      <td>Steins;Gate</td>
      <td>3</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>8.726812</td>
      <td>341</td>
      <td>628071</td>
      <td>16610</td>
      <td>68383</td>
      <td>262806</td>
      <td>24425</td>
      <td>18685</td>
      <td>253772</td>
      <td>628071</td>
      <td>...</td>
      <td>6060</td>
      <td>3601</td>
      <td>1496</td>
      <td>1011</td>
      <td>1477</td>
      <td>8616</td>
      <td>28977</td>
      <td>Gintama°</td>
      <td>4</td>
      <td>51.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>9.019487</td>
      <td>21</td>
      <td>2262916</td>
      <td>58383</td>
      <td>79195</td>
      <td>2037246</td>
      <td>9242</td>
      <td>7393</td>
      <td>129840</td>
      <td>2262916</td>
      <td>...</td>
      <td>22287</td>
      <td>8112</td>
      <td>3186</td>
      <td>1596</td>
      <td>1308</td>
      <td>12803</td>
      <td>38524</td>
      <td>Shingeki no Kyojin Season 3 Part 2</td>
      <td>5</td>
      <td>10.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 24 columns</p>
</div>




```python
ax = sns.histplot(scores, x='Score')

quantiles = ['25%','50%','75%']
colors = ['red','orange','green']
for i in range(len(quantiles)):
    a = scores.describe().transpose()[quantiles[i]]['Score']
    ax.axvline(a, color=colors[i], label=f'Q{i+1} : {a:.2f}')
plt.legend()
plt.title('Distribution of Scores Across All Titles')
```




    Text(0.5, 1.0, 'Distribution of Scores Across All Titles')




    
![png](/images/mal_eda/output_59_1.png)
    


Looking at the distribution of scores for all titles we see that most scores fall between 5.83~7.21.

The distribution suggests that users are not using the entire scale, rather than a 1-10 rating system it looks more like a 4-10 system with 6/7 being an "average" rating.

Next we can try looking at the deviation of scores to see which are the more polarizing titles according to user ratings.


```python
def calc_sd(data):
    #MAD = (summ |xi - xmean|) / n
    n = 0
    total = 0
    xmean = 0
    xdiff = 0
    for i in range(1,11):
        col = 'Score-' + str(i)
        total += data[col] * int(i)
        n += data[col]
        
    xmean = total/n
    
    for i in range(1,11):
        col = 'Score-' + str(i)
        xdiff += (abs(int(i)-xmean) ** 2) * data[col]
    return (xdiff/n) ** 0.5
```


```python
scores['SD'] = scores.apply(calc_sd, axis=1)
scores['SD']
```




    0        1.361661
    1        1.674361
    2        1.430520
    3        2.009090
    4        1.289965
               ...   
    13295    3.203730
    13296    1.950239
    13297    2.841099
    13298    2.860655
    13299    3.108680
    Name: SD, Length: 13300, dtype: float64




```python
scores[['Name','Rank','Score','SD','Popularity']].sort_values('SD', ascending = False)[:10]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Rank</th>
      <th>Score</th>
      <th>SD</th>
      <th>Popularity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>13288</th>
      <td>Shin Yaranai ka</td>
      <td>13289</td>
      <td>6.631579</td>
      <td>3.615908</td>
      <td>10908</td>
    </tr>
    <tr>
      <th>13159</th>
      <td>Chicken Papa</td>
      <td>13160</td>
      <td>4.150509</td>
      <td>3.381850</td>
      <td>10311</td>
    </tr>
    <tr>
      <th>12363</th>
      <td>Uobbuchou</td>
      <td>12364</td>
      <td>4.731707</td>
      <td>3.325372</td>
      <td>18258</td>
    </tr>
    <tr>
      <th>11684</th>
      <td>Kenda Master Ken (TV)</td>
      <td>11685</td>
      <td>5.150235</td>
      <td>3.323831</td>
      <td>13899</td>
    </tr>
    <tr>
      <th>10645</th>
      <td>Mahou no LumiTear</td>
      <td>10646</td>
      <td>7.172691</td>
      <td>3.320603</td>
      <td>14605</td>
    </tr>
    <tr>
      <th>10853</th>
      <td>Yousei Dick</td>
      <td>10854</td>
      <td>5.659574</td>
      <td>3.316795</td>
      <td>14295</td>
    </tr>
    <tr>
      <th>12335</th>
      <td>Yodel no Onna</td>
      <td>12336</td>
      <td>5.741093</td>
      <td>3.316546</td>
      <td>12113</td>
    </tr>
    <tr>
      <th>11676</th>
      <td>Burutabu-chan</td>
      <td>11677</td>
      <td>4.396694</td>
      <td>3.296578</td>
      <td>18372</td>
    </tr>
    <tr>
      <th>13015</th>
      <td>Chargeman Ken!</td>
      <td>13016</td>
      <td>4.353383</td>
      <td>3.259139</td>
      <td>8821</td>
    </tr>
    <tr>
      <th>10239</th>
      <td>Xiong Chumo: Xiong Zin Guilai</td>
      <td>10240</td>
      <td>4.469027</td>
      <td>3.256228</td>
      <td>18319</td>
    </tr>
  </tbody>
</table>
</div>




```python
score_cols = ['Score-10', 'Score-9',
       'Score-8', 'Score-7', 'Score-6', 'Score-5', 'Score-4', 'Score-3',
       'Score-2', 'Score-1'][::-1]
ax = sns.barplot(scores[scores['Rank']==13016][score_cols])
ax.set_xticklabels(score_cols, rotation=45, ha='right')

```




    [Text(0, 0, 'Score-1'),
     Text(1, 0, 'Score-2'),
     Text(2, 0, 'Score-3'),
     Text(3, 0, 'Score-4'),
     Text(4, 0, 'Score-5'),
     Text(5, 0, 'Score-6'),
     Text(6, 0, 'Score-7'),
     Text(7, 0, 'Score-8'),
     Text(8, 0, 'Score-9'),
     Text(9, 0, 'Score-10')]




    
![png](/images/mal_eda/output_64_1.png)
    



```python
scores[scores['Rank']==13016][score_cols]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Score-1</th>
      <th>Score-2</th>
      <th>Score-3</th>
      <th>Score-4</th>
      <th>Score-5</th>
      <th>Score-6</th>
      <th>Score-7</th>
      <th>Score-8</th>
      <th>Score-9</th>
      <th>Score-10</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>13015</th>
      <td>404</td>
      <td>227</td>
      <td>206</td>
      <td>149</td>
      <td>130</td>
      <td>72</td>
      <td>62</td>
      <td>35</td>
      <td>30</td>
      <td>281</td>
    </tr>
  </tbody>
</table>
</div>



Looks like Titles with the largest score deviation are generally lower scoring titles with lower popularity. Possibly due to the lower number of user votes and obscurity of the title, the title will be dominated by scores at both ends of the 1-10 scale rather than the centre/one end of the scale as one would expect.


```python
scores[['Name','Rank','Score','SD','Popularity']].loc[scores['Rank'] < 300].sort_values('SD', ascending = False)[:10]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Rank</th>
      <th>Score</th>
      <th>SD</th>
      <th>Popularity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>9</th>
      <td>Ginga Eiyuu Densetsu</td>
      <td>10</td>
      <td>8.647633</td>
      <td>2.177381</td>
      <td>745</td>
    </tr>
    <tr>
      <th>49</th>
      <td>Ashita no Joe 2</td>
      <td>50</td>
      <td>8.380418</td>
      <td>2.172501</td>
      <td>3045</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Gintama: The Final</td>
      <td>6</td>
      <td>8.862701</td>
      <td>2.126664</td>
      <td>1538</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Gintama°</td>
      <td>4</td>
      <td>8.726812</td>
      <td>2.009090</td>
      <td>341</td>
    </tr>
    <tr>
      <th>272</th>
      <td>Blue Archive the Animation</td>
      <td>273</td>
      <td>8.379562</td>
      <td>1.946342</td>
      <td>4056</td>
    </tr>
    <tr>
      <th>143</th>
      <td>Mo Dao Zu Shi: Wanjie Pian</td>
      <td>144</td>
      <td>8.427876</td>
      <td>1.929255</td>
      <td>2377</td>
    </tr>
    <tr>
      <th>160</th>
      <td>Gintama: Yorinuki Gintama-san on Theater 2D</td>
      <td>161</td>
      <td>8.295726</td>
      <td>1.914696</td>
      <td>3306</td>
    </tr>
    <tr>
      <th>139</th>
      <td>Aria the Origination</td>
      <td>140</td>
      <td>8.325882</td>
      <td>1.849753</td>
      <td>1725</td>
    </tr>
    <tr>
      <th>227</th>
      <td>Tian Guan Cifu Special</td>
      <td>228</td>
      <td>8.325569</td>
      <td>1.834084</td>
      <td>3157</td>
    </tr>
    <tr>
      <th>208</th>
      <td>Ramayana: The Legend of Prince Rama</td>
      <td>209</td>
      <td>8.390935</td>
      <td>1.804288</td>
      <td>6079</td>
    </tr>
  </tbody>
</table>
</div>




```python
score_cols = ['Score-10', 'Score-9',
       'Score-8', 'Score-7', 'Score-6', 'Score-5', 'Score-4', 'Score-3',
       'Score-2', 'Score-1'][::-1]
ax = sns.barplot(scores[scores['Rank']==10][score_cols])
ax.set_xticklabels(score_cols, rotation=45, ha='right')

```




    [Text(0, 0, 'Score-1'),
     Text(1, 0, 'Score-2'),
     Text(2, 0, 'Score-3'),
     Text(3, 0, 'Score-4'),
     Text(4, 0, 'Score-5'),
     Text(5, 0, 'Score-6'),
     Text(6, 0, 'Score-7'),
     Text(7, 0, 'Score-8'),
     Text(8, 0, 'Score-9'),
     Text(9, 0, 'Score-10')]




    
![png](/images/mal_eda/output_68_1.png)
    


Looking at only the Top 300 titles we see the highest standard deviation of scores is significantly lower at ~2.18. Compared to the previous title, we see that this title appears to be universally well acclaimed with a large amount of perfect scores. The variance in scores appear to be driven up by a sizeable subset of users giving it a score of 1.


```python
scores['PauseWatchRatio'] = (scores['Dropped']+scores['On-Hold'])/(scores['Completed']+scores['Watching'])
```


```python
scores[['Rank','Name','Score','Episodes','PauseWatchRatio','Popularity']].iloc[:100].sort_values('PauseWatchRatio', ascending=False)[:10]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Rank</th>
      <th>Name</th>
      <th>Score</th>
      <th>Episodes</th>
      <th>PauseWatchRatio</th>
      <th>Popularity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>14</th>
      <td>15</td>
      <td>Gintama</td>
      <td>8.616600</td>
      <td>201.0</td>
      <td>0.332894</td>
      <td>139</td>
    </tr>
    <tr>
      <th>51</th>
      <td>52</td>
      <td>One Piece</td>
      <td>8.741164</td>
      <td>NaN</td>
      <td>0.280334</td>
      <td>19</td>
    </tr>
    <tr>
      <th>9</th>
      <td>10</td>
      <td>Ginga Eiyuu Densetsu</td>
      <td>8.647633</td>
      <td>110.0</td>
      <td>0.268197</td>
      <td>745</td>
    </tr>
    <tr>
      <th>69</th>
      <td>70</td>
      <td>Mushishi</td>
      <td>8.542181</td>
      <td>26.0</td>
      <td>0.219599</td>
      <td>215</td>
    </tr>
    <tr>
      <th>24</th>
      <td>25</td>
      <td>Monster</td>
      <td>8.753179</td>
      <td>74.0</td>
      <td>0.209530</td>
      <td>133</td>
    </tr>
    <tr>
      <th>99</th>
      <td>100</td>
      <td>Shouwa Genroku Rakugo Shinjuu</td>
      <td>8.477288</td>
      <td>13.0</td>
      <td>0.170704</td>
      <td>833</td>
    </tr>
    <tr>
      <th>57</th>
      <td>58</td>
      <td>Great Teacher Onizuka</td>
      <td>8.611780</td>
      <td>43.0</td>
      <td>0.137601</td>
      <td>218</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Gintama°</td>
      <td>8.726812</td>
      <td>51.0</td>
      <td>0.130167</td>
      <td>341</td>
    </tr>
    <tr>
      <th>45</th>
      <td>46</td>
      <td>Cowboy Bebop</td>
      <td>8.710319</td>
      <td>26.0</td>
      <td>0.119984</td>
      <td>43</td>
    </tr>
    <tr>
      <th>50</th>
      <td>51</td>
      <td>Shouwa Genroku Rakugo Shinjuu: Sukeroku Futata...</td>
      <td>8.608779</td>
      <td>12.0</td>
      <td>0.114479</td>
      <td>1272</td>
    </tr>
  </tbody>
</table>
</div>



Within the top 100 titles, when comparing the ratio of users who have dropped/paused the title vs those who have completed/currently-watching, the top three titles with the highest ratio of watchers abandoning the show all have a high number of episodes with approximately 1/3 ~ 1/4 of watchers abandoning it partway. One Piece has more than 1000 episodes as of 2024.

Even though these titles are highly rated and generally high in popularity, it appears that the length of a series is a factor in whether a user watches a titles completely.


```python
sns.heatmap(scores.iloc[:100].corr(numeric_only=True), mask = np.triu(scores.iloc[:100].corr(numeric_only=True)))
```




    <Axes: >




    
![png](/images/mal_eda/output_73_1.png)
    


Looking at the heatmap above for the top 100 titles, it looks like number of Episodes is indeed linearly correlated with PauseWatchRatio. Another interesting observation is that a title's average score is correlated to the number of Score-1 that it has received, suggesting that highly rated titles may be bombarded by Score-1 ratings for whatever reason.


```python
sns.heatmap(cleaned_df.corr(numeric_only=True), mask = np.triu(cleaned_df.corr(numeric_only=True)), cmap='icefire')
```




    <Axes: >




    
![png](/images/mal_eda/output_75_1.png)
    


Above we see a correlation heatmap of the variables within our dataset, with many observations that aligns with what one would commonly expect. Titles' ratings/popularity are correlated the number of times they get added to a user's to-watch list.

<a id='3'></a>
## 3. Anime Reviews Dataset EDA


```python
df = pd.read_csv('cleaned_anime_reviews.csv')
df2 = df.merge(cleaned_df[['MAL_Id','Name','Type','Episodes','Status','Source','Aired_Start','Aired_End','Rank']])
df2
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>review_id</th>
      <th>MAL_Id</th>
      <th>Review</th>
      <th>Tags</th>
      <th>Name</th>
      <th>Type</th>
      <th>Episodes</th>
      <th>Status</th>
      <th>Source</th>
      <th>Aired_Start</th>
      <th>Aired_End</th>
      <th>Rank</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>52991</td>
      <td>With lives so short, why do we even bother? To...</td>
      <td>Recommended</td>
      <td>Sousou no Frieren</td>
      <td>TV</td>
      <td>28.0</td>
      <td>Finished Airing</td>
      <td>Manga</td>
      <td>2023-09-29</td>
      <td>2024-03-22</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>52991</td>
      <td>With lives so short, why do we even bother? To...</td>
      <td>Preliminary</td>
      <td>Sousou no Frieren</td>
      <td>TV</td>
      <td>28.0</td>
      <td>Finished Airing</td>
      <td>Manga</td>
      <td>2023-09-29</td>
      <td>2024-03-22</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>52991</td>
      <td>Frieren is the most overrated anime of this de...</td>
      <td>Not-Recommended</td>
      <td>Sousou no Frieren</td>
      <td>TV</td>
      <td>28.0</td>
      <td>Finished Airing</td>
      <td>Manga</td>
      <td>2023-09-29</td>
      <td>2024-03-22</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>52991</td>
      <td>Frieren is the most overrated anime of this de...</td>
      <td>Funny</td>
      <td>Sousou no Frieren</td>
      <td>TV</td>
      <td>28.0</td>
      <td>Finished Airing</td>
      <td>Manga</td>
      <td>2023-09-29</td>
      <td>2024-03-22</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>52991</td>
      <td>Frieren is the most overrated anime of this de...</td>
      <td>Preliminary</td>
      <td>Sousou no Frieren</td>
      <td>TV</td>
      <td>28.0</td>
      <td>Finished Airing</td>
      <td>Manga</td>
      <td>2023-09-29</td>
      <td>2024-03-22</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>92327</th>
      <td>77912</td>
      <td>3287</td>
      <td>Anime is and always has been, a great story te...</td>
      <td>Not-Recommended</td>
      <td>Tenkuu Danzai Skelter+Heaven</td>
      <td>OVA</td>
      <td>1.0</td>
      <td>Finished Airing</td>
      <td>Visual novel</td>
      <td>2004-12-08</td>
      <td>NaT</td>
      <td>13284</td>
    </tr>
    <tr>
      <th>92328</th>
      <td>77913</td>
      <td>3287</td>
      <td>If you've come to watch a piece of trash, then...</td>
      <td>Not-Recommended</td>
      <td>Tenkuu Danzai Skelter+Heaven</td>
      <td>OVA</td>
      <td>1.0</td>
      <td>Finished Airing</td>
      <td>Visual novel</td>
      <td>2004-12-08</td>
      <td>NaT</td>
      <td>13284</td>
    </tr>
    <tr>
      <th>92329</th>
      <td>77914</td>
      <td>3287</td>
      <td>Giant Sqid Thingy is muh waifu Before there wa...</td>
      <td>Recommended</td>
      <td>Tenkuu Danzai Skelter+Heaven</td>
      <td>OVA</td>
      <td>1.0</td>
      <td>Finished Airing</td>
      <td>Visual novel</td>
      <td>2004-12-08</td>
      <td>NaT</td>
      <td>13284</td>
    </tr>
    <tr>
      <th>92330</th>
      <td>77915</td>
      <td>3287</td>
      <td>"It is not the fault of the product. It depend...</td>
      <td>Recommended</td>
      <td>Tenkuu Danzai Skelter+Heaven</td>
      <td>OVA</td>
      <td>1.0</td>
      <td>Finished Airing</td>
      <td>Visual novel</td>
      <td>2004-12-08</td>
      <td>NaT</td>
      <td>13284</td>
    </tr>
    <tr>
      <th>92331</th>
      <td>77916</td>
      <td>3287</td>
      <td>"Tenkuu Danzai Skelter+Heaven" is a thrilling ...</td>
      <td>Recommended</td>
      <td>Tenkuu Danzai Skelter+Heaven</td>
      <td>OVA</td>
      <td>1.0</td>
      <td>Finished Airing</td>
      <td>Visual novel</td>
      <td>2004-12-08</td>
      <td>NaT</td>
      <td>13284</td>
    </tr>
  </tbody>
</table>
<p>92332 rows × 12 columns</p>
</div>




```python
df2.groupby('MAL_Id')['review_id'].nunique().value_counts()
```




    review_id
    20    2257
    1     2004
    2     1141
    3      777
    4      575
    5      397
    6      321
    7      262
    8      239
    9      177
    10     170
    12     133
    11     127
    14     114
    13     114
    15     102
    17      89
    16      79
    18      71
    19      66
    Name: count, dtype: int64



The max number of reviews for any title within the dataset appears to be 20 as the source scrapes only the first page of reviews for every title.


```python
print(f"Titles with at least a full page of reviews: {(df2.groupby('MAL_Id')['review_id'].nunique() == 20).sum()} / {len(df2.groupby('MAL_Id')['review_id'].nunique())} titles")
```

    Titles with at least a full page of reviews: 2257 / 9215 titles
    


```python
# Count length of each review 
df2['review_length'] = df2.Review.apply(len)
df2['review_length'].head()
```




    0    3381
    1    3381
    2    1458
    3    1458
    4    1458
    Name: review_length, dtype: int64




```python
# collate unique review per MAL id
review_len = df2.groupby('MAL_Id')['review_id'].unique().reset_index()
review_len.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MAL_Id</th>
      <th>review_id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>[892, 893, 894, 895, 896, 897, 898, 899, 900, ...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5</td>
      <td>[3486, 3487, 3488, 3489, 3490, 3491, 3492, 349...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>6</td>
      <td>[6023, 6024, 6025, 6026, 6027, 6028, 6029, 603...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7</td>
      <td>[37039, 37040, 37041, 37042, 37043, 37044, 370...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>8</td>
      <td>[48684, 48685, 48686, 48687]</td>
    </tr>
  </tbody>
</table>
</div>




```python
def sum_reviews(data, ref=df2):
    reviews_len = 0
    for num in data['review_id']:
        reviews_len += ref.loc[ref.review_id == num]['review_length'].values[0]
    return reviews_len
```


```python
# Total length of all reviews per MAL Id
review_len['total_review_length'] = review_len.apply(sum_reviews, axis=1)
review_len.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MAL_Id</th>
      <th>review_id</th>
      <th>total_review_length</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>[892, 893, 894, 895, 896, 897, 898, 899, 900, ...</td>
      <td>112849</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5</td>
      <td>[3486, 3487, 3488, 3489, 3490, 3491, 3492, 349...</td>
      <td>54635</td>
    </tr>
    <tr>
      <th>2</th>
      <td>6</td>
      <td>[6023, 6024, 6025, 6026, 6027, 6028, 6029, 603...</td>
      <td>93273</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7</td>
      <td>[37039, 37040, 37041, 37042, 37043, 37044, 370...</td>
      <td>47901</td>
    </tr>
    <tr>
      <th>4</th>
      <td>8</td>
      <td>[48684, 48685, 48686, 48687]</td>
      <td>5808</td>
    </tr>
  </tbody>
</table>
</div>




```python
review_len = review_len.merge(cleaned_df[['MAL_Id','Name','Rank']], how = 'left')
review_len = review_len.merge(df2.groupby('MAL_Id')['Tags'].value_counts().unstack().reset_index(), how = 'left')
review_len.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MAL_Id</th>
      <th>review_id</th>
      <th>total_review_length</th>
      <th>Name</th>
      <th>Rank</th>
      <th>Creative</th>
      <th>Funny</th>
      <th>Informative</th>
      <th>Mixed-Feelings</th>
      <th>Not-Recommended</th>
      <th>Preliminary</th>
      <th>Recommended</th>
      <th>Well-written</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>[892, 893, 894, 895, 896, 897, 898, 899, 900, ...</td>
      <td>112849</td>
      <td>Cowboy Bebop</td>
      <td>46</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>15.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5</td>
      <td>[3486, 3487, 3488, 3489, 3490, 3491, 3492, 349...</td>
      <td>54635</td>
      <td>Cowboy Bebop: Tengoku no Tobira</td>
      <td>191</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>16.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>6</td>
      <td>[6023, 6024, 6025, 6026, 6027, 6028, 6029, 603...</td>
      <td>93273</td>
      <td>Trigun</td>
      <td>347</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>16.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7</td>
      <td>[37039, 37040, 37041, 37042, 37043, 37044, 370...</td>
      <td>47901</td>
      <td>Witch Hunter Robin</td>
      <td>3035</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>15.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>8</td>
      <td>[48684, 48685, 48686, 48687]</td>
      <td>5808</td>
      <td>Bouken Ou Beet</td>
      <td>4538</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>3.0</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>




```python
review_len.sort_values('total_review_length', ascending=False)[:10]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MAL_Id</th>
      <th>review_id</th>
      <th>total_review_length</th>
      <th>Name</th>
      <th>Rank</th>
      <th>Creative</th>
      <th>Funny</th>
      <th>Informative</th>
      <th>Mixed-Feelings</th>
      <th>Not-Recommended</th>
      <th>Preliminary</th>
      <th>Recommended</th>
      <th>Well-written</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4164</th>
      <td>11061</td>
      <td>[120, 121, 122, 123, 124, 125, 126, 127, 128, ...</td>
      <td>204133</td>
      <td>Hunter x Hunter (2011)</td>
      <td>7</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>14.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>693</th>
      <td>820</td>
      <td>[180, 181, 182, 183, 184, 185, 186, 187, 188, ...</td>
      <td>190299</td>
      <td>Ginga Eiyuu Densetsu</td>
      <td>10</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>13.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6815</th>
      <td>35849</td>
      <td>[38696, 38697, 38698, 38699, 38700, 38701, 387...</td>
      <td>184702</td>
      <td>Darling in the FranXX</td>
      <td>3229</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>8.0</td>
      <td>10.0</td>
      <td>11.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5823</th>
      <td>31043</td>
      <td>[4564, 4565, 4566, 4567, 4568, 4569, 4570, 457...</td>
      <td>164640</td>
      <td>Boku dake ga Inai Machi</td>
      <td>257</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>3.0</td>
      <td>8.0</td>
      <td>1.0</td>
      <td>9.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>6207</th>
      <td>32981</td>
      <td>[75369, 75370, 75371, 75372, 75373, 75374, 753...</td>
      <td>158419</td>
      <td>Hand Shakers</td>
      <td>12228</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>14.0</td>
      <td>9.0</td>
      <td>4.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5130</th>
      <td>21881</td>
      <td>[55394, 55395, 55396, 55397, 55398, 55399, 554...</td>
      <td>158184</td>
      <td>Sword Art Online II</td>
      <td>5636</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4.0</td>
      <td>8.0</td>
      <td>NaN</td>
      <td>8.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>8285</th>
      <td>45576</td>
      <td>[1222, 1223, 1224, 1225, 1226, 1227, 1228, 122...</td>
      <td>157586</td>
      <td>Mushoku Tensei: Isekai Ittara Honki Dasu Part 2</td>
      <td>64</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>10.0</td>
      <td>7.0</td>
      <td>9.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>8766</th>
      <td>51009</td>
      <td>[540, 541, 542, 543, 544, 545, 546, 547, 548, ...</td>
      <td>156426</td>
      <td>Jujutsu Kaisen 2nd Season</td>
      <td>28</td>
      <td>NaN</td>
      <td>10.0</td>
      <td>NaN</td>
      <td>8.0</td>
      <td>6.0</td>
      <td>11.0</td>
      <td>6.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4075</th>
      <td>10620</td>
      <td>[29907, 29908, 29909, 29910, 29911, 29912, 299...</td>
      <td>150197</td>
      <td>Mirai Nikki (TV)</td>
      <td>2264</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>3.0</td>
      <td>9.0</td>
      <td>2.0</td>
      <td>8.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4880</th>
      <td>18679</td>
      <td>[9774, 9775, 9776, 9777, 9778, 9779, 9780, 978...</td>
      <td>147220</td>
      <td>Kill la Kill</td>
      <td>588</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4.0</td>
      <td>3.0</td>
      <td>NaN</td>
      <td>13.0</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>



Hunter X Hunter (2011) has the longest reviews in the first page with a total of over 200,000 characters!


```python
tmp = (df2.groupby('MAL_Id')['review_id'].nunique() == 20).reset_index()
tmp = tmp[tmp['review_id'] == True]['MAL_Id'].values
review_len[review_len['MAL_Id'].isin(tmp)].shape
```




    (2257, 13)




```python
ax = sns.histplot(review_len[review_len['MAL_Id'].isin(tmp)], x='total_review_length')
quantiles = ['25%','50%','75%']
colors = ['red','orange','green']
for i in range(len(quantiles)):
    a = review_len[review_len['MAL_Id'].isin(tmp)].describe()['total_review_length'].transpose()[quantiles[i]]
    ax.axvline(a, color=colors[i], label=f'Q{i+1} : {a:.2f}')
plt.legend()
plt.title('Distribution of Total Review Length (Titles with Full First Page of Reviews)')
```




    Text(0.5, 1.0, 'Distribution of Total Review Length (Titles with Full First Page of Reviews)')




    
![png](/images/mal_eda/output_89_1.png)
    


Most titles with a filled first page have between 47000 to 77000 total review characters on the first page.

<a id='4'></a>
## 4. User Ratings Dataset EDA
In the final section we will be exploring the user ratings dataset guided by the following questions
1. [Average number of titles on a user's list?](#4.1)
2. [Average number of lists a title is added to?](#4.2)
3. [Is this dataset representative of the population data?](#4.3)



```python
df = pd.read_csv('cleaned_user_ratings.csv')
df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Username</th>
      <th>User_Id</th>
      <th>Anime_Id</th>
      <th>Anime_Title</th>
      <th>Rating_Status</th>
      <th>Rating_Score</th>
      <th>Num_Epi_Watched</th>
      <th>Is_Rewatching</th>
      <th>Updated</th>
      <th>Start_Date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>flerbz</td>
      <td>0</td>
      <td>30654</td>
      <td>Ansatsu Kyoushitsu 2nd Season</td>
      <td>watching</td>
      <td>0</td>
      <td>24</td>
      <td>False</td>
      <td>2022-02-26 22:15:01+00:00</td>
      <td>2022-01-29</td>
    </tr>
    <tr>
      <th>1</th>
      <td>flerbz</td>
      <td>0</td>
      <td>22789</td>
      <td>Barakamon</td>
      <td>dropped</td>
      <td>0</td>
      <td>2</td>
      <td>False</td>
      <td>2023-01-28 19:03:33+00:00</td>
      <td>2022-04-06</td>
    </tr>
    <tr>
      <th>2</th>
      <td>flerbz</td>
      <td>0</td>
      <td>31964</td>
      <td>Boku no Hero Academia</td>
      <td>completed</td>
      <td>0</td>
      <td>13</td>
      <td>False</td>
      <td>2024-03-31 02:10:32+00:00</td>
      <td>2024-03-30</td>
    </tr>
    <tr>
      <th>3</th>
      <td>flerbz</td>
      <td>0</td>
      <td>33486</td>
      <td>Boku no Hero Academia 2nd Season</td>
      <td>completed</td>
      <td>0</td>
      <td>25</td>
      <td>False</td>
      <td>2024-03-31 22:32:02+00:00</td>
      <td>2024-03-30</td>
    </tr>
    <tr>
      <th>4</th>
      <td>flerbz</td>
      <td>0</td>
      <td>36456</td>
      <td>Boku no Hero Academia 3rd Season</td>
      <td>watching</td>
      <td>0</td>
      <td>24</td>
      <td>False</td>
      <td>2024-04-03 02:08:56+00:00</td>
      <td>2024-03-31</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>5452187</th>
      <td>mintcakee</td>
      <td>20010</td>
      <td>392</td>
      <td>Yuu☆Yuu☆Hakusho</td>
      <td>plan_to_watch</td>
      <td>0</td>
      <td>0</td>
      <td>False</td>
      <td>2023-03-09 13:18:23+00:00</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5452188</th>
      <td>mintcakee</td>
      <td>20010</td>
      <td>1246</td>
      <td>Yuugo: Koushounin</td>
      <td>plan_to_watch</td>
      <td>0</td>
      <td>0</td>
      <td>False</td>
      <td>2023-10-23 14:14:44+00:00</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5452189</th>
      <td>mintcakee</td>
      <td>20010</td>
      <td>23283</td>
      <td>Zankyou no Terror</td>
      <td>plan_to_watch</td>
      <td>0</td>
      <td>0</td>
      <td>False</td>
      <td>2022-12-29 02:18:00+00:00</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5452190</th>
      <td>mintcakee</td>
      <td>20010</td>
      <td>37976</td>
      <td>Zombieland Saga</td>
      <td>completed</td>
      <td>7</td>
      <td>12</td>
      <td>False</td>
      <td>2023-04-24 14:35:42+00:00</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5452191</th>
      <td>mintcakee</td>
      <td>20010</td>
      <td>40174</td>
      <td>Zombieland Saga Revenge</td>
      <td>completed</td>
      <td>8</td>
      <td>12</td>
      <td>False</td>
      <td>2023-04-24 14:35:46+00:00</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>5452192 rows × 10 columns</p>
</div>




```python
df.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 5452192 entries, 0 to 5452191
    Data columns (total 10 columns):
     #   Column           Dtype 
    ---  ------           ----- 
     0   Username         object
     1   User_Id          int64 
     2   Anime_Id         int64 
     3   Anime_Title      object
     4   Rating_Status    object
     5   Rating_Score     int64 
     6   Num_Epi_Watched  int64 
     7   Is_Rewatching    bool  
     8   Updated          object
     9   Start_Date       object
    dtypes: bool(1), int64(4), object(5)
    memory usage: 379.6+ MB
    

<a id='4.1'></a>
### 4.1 Average Number of titles on a user's list?


```python
print(f'Dataset contains {df.Username.nunique()} unique usernames')
```

    Dataset contains 17513 unique usernames
    


```python
df.Rating_Status.value_counts()
```




    Rating_Status
    completed        3495469
    plan_to_watch    1354615
    watching          276342
    dropped           190743
    on_hold           134890
    Name: count, dtype: int64




```python
df.Rating_Score.value_counts()
```




    Rating_Score
    0     2483410
    8      760247
    7      697199
    9      476260
    6      355335
    10     331937
    5      179752
    4       82215
    3       40177
    2       23248
    1       22412
    Name: count, dtype: int64




```python
print(f'{(len(df)-df.Rating_Score.value_counts()[0])*100/len(df):.2f}% of the entries in the dataset have not been rated')
```

    54.45% of the entries in the dataset have not been rated
    


```python
df.groupby('Username').count()['User_Id'].describe()
```




    count    17513.00000
    mean       311.32256
    std        174.44065
    min          1.00000
    25%        153.00000
    50%        327.00000
    75%        499.00000
    max        499.00000
    Name: User_Id, dtype: float64




```python
ax = sns.histplot(df.groupby('Username').count()[['User_Id']], x='User_Id')
quantiles = ['25%','50%','75%']
colors = ['red','orange','green']
for i in range(len(quantiles)):
    a = df.groupby('Username').count()['User_Id'].describe().transpose()[quantiles[i]]
    ax.axvline(a, color=colors[i], label=f'Q{i+1} : {a:.2f}')
plt.xlabel('Number of Entries in List')
plt.legend()
plt.title('Distribution of Number of Titles in User List')
```




    Text(0.5, 1.0, 'Distribution of Number of Titles in User List')




    
![png](/images/mal_eda/output_100_1.png)
    


We see that max number of titles in a list is 500, this is due to the webscraping script setting a limit of titles per username to 500, hence the 5000+ usernames with 499 titles in their lists

Within the dataset we see that most users have between 153 to 499 titles in their list.


```python
df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Username</th>
      <th>User_Id</th>
      <th>Anime_Id</th>
      <th>Anime_Title</th>
      <th>Rating_Status</th>
      <th>Rating_Score</th>
      <th>Num_Epi_Watched</th>
      <th>Is_Rewatching</th>
      <th>Updated</th>
      <th>Start_Date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>flerbz</td>
      <td>0</td>
      <td>30654</td>
      <td>Ansatsu Kyoushitsu 2nd Season</td>
      <td>watching</td>
      <td>0</td>
      <td>24</td>
      <td>False</td>
      <td>2022-02-26 22:15:01+00:00</td>
      <td>2022-01-29</td>
    </tr>
    <tr>
      <th>1</th>
      <td>flerbz</td>
      <td>0</td>
      <td>22789</td>
      <td>Barakamon</td>
      <td>dropped</td>
      <td>0</td>
      <td>2</td>
      <td>False</td>
      <td>2023-01-28 19:03:33+00:00</td>
      <td>2022-04-06</td>
    </tr>
    <tr>
      <th>2</th>
      <td>flerbz</td>
      <td>0</td>
      <td>31964</td>
      <td>Boku no Hero Academia</td>
      <td>completed</td>
      <td>0</td>
      <td>13</td>
      <td>False</td>
      <td>2024-03-31 02:10:32+00:00</td>
      <td>2024-03-30</td>
    </tr>
    <tr>
      <th>3</th>
      <td>flerbz</td>
      <td>0</td>
      <td>33486</td>
      <td>Boku no Hero Academia 2nd Season</td>
      <td>completed</td>
      <td>0</td>
      <td>25</td>
      <td>False</td>
      <td>2024-03-31 22:32:02+00:00</td>
      <td>2024-03-30</td>
    </tr>
    <tr>
      <th>4</th>
      <td>flerbz</td>
      <td>0</td>
      <td>36456</td>
      <td>Boku no Hero Academia 3rd Season</td>
      <td>watching</td>
      <td>0</td>
      <td>24</td>
      <td>False</td>
      <td>2024-04-03 02:08:56+00:00</td>
      <td>2024-03-31</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>5452187</th>
      <td>mintcakee</td>
      <td>20010</td>
      <td>392</td>
      <td>Yuu☆Yuu☆Hakusho</td>
      <td>plan_to_watch</td>
      <td>0</td>
      <td>0</td>
      <td>False</td>
      <td>2023-03-09 13:18:23+00:00</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5452188</th>
      <td>mintcakee</td>
      <td>20010</td>
      <td>1246</td>
      <td>Yuugo: Koushounin</td>
      <td>plan_to_watch</td>
      <td>0</td>
      <td>0</td>
      <td>False</td>
      <td>2023-10-23 14:14:44+00:00</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5452189</th>
      <td>mintcakee</td>
      <td>20010</td>
      <td>23283</td>
      <td>Zankyou no Terror</td>
      <td>plan_to_watch</td>
      <td>0</td>
      <td>0</td>
      <td>False</td>
      <td>2022-12-29 02:18:00+00:00</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5452190</th>
      <td>mintcakee</td>
      <td>20010</td>
      <td>37976</td>
      <td>Zombieland Saga</td>
      <td>completed</td>
      <td>7</td>
      <td>12</td>
      <td>False</td>
      <td>2023-04-24 14:35:42+00:00</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>5452191</th>
      <td>mintcakee</td>
      <td>20010</td>
      <td>40174</td>
      <td>Zombieland Saga Revenge</td>
      <td>completed</td>
      <td>8</td>
      <td>12</td>
      <td>False</td>
      <td>2023-04-24 14:35:46+00:00</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>5452192 rows × 10 columns</p>
</div>




```python
# Calculate percentage of rated entries in a user's list
df_rated = df[df.Rating_Score != 0].groupby('Username').count()[['User_Id']].reset_index()
df_all = df.groupby('Username').count()['User_Id'].reset_index()
tmp = df_rated.merge(df_all, how = 'left', on ='Username')
tmp['Percentage'] = tmp['User_Id_x']/tmp['User_Id_y']
tmp
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Username</th>
      <th>User_Id_x</th>
      <th>User_Id_y</th>
      <th>Percentage</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>---NovA---</td>
      <td>343</td>
      <td>375</td>
      <td>0.914667</td>
    </tr>
    <tr>
      <th>1</th>
      <td>--0__0--</td>
      <td>11</td>
      <td>241</td>
      <td>0.045643</td>
    </tr>
    <tr>
      <th>2</th>
      <td>--Amaya--</td>
      <td>198</td>
      <td>449</td>
      <td>0.440980</td>
    </tr>
    <tr>
      <th>3</th>
      <td>--Maple--</td>
      <td>318</td>
      <td>391</td>
      <td>0.813299</td>
    </tr>
    <tr>
      <th>4</th>
      <td>--Xerxes--</td>
      <td>181</td>
      <td>396</td>
      <td>0.457071</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>16149</th>
      <td>zozon</td>
      <td>33</td>
      <td>499</td>
      <td>0.066132</td>
    </tr>
    <tr>
      <th>16150</th>
      <td>zsda2</td>
      <td>282</td>
      <td>322</td>
      <td>0.875776</td>
    </tr>
    <tr>
      <th>16151</th>
      <td>zulfikar12</td>
      <td>130</td>
      <td>135</td>
      <td>0.962963</td>
    </tr>
    <tr>
      <th>16152</th>
      <td>zumiyu</td>
      <td>2</td>
      <td>245</td>
      <td>0.008163</td>
    </tr>
    <tr>
      <th>16153</th>
      <td>zun43d</td>
      <td>37</td>
      <td>330</td>
      <td>0.112121</td>
    </tr>
  </tbody>
</table>
<p>16154 rows × 4 columns</p>
</div>




```python
tmp.Percentage.describe()
```




    count    16154.000000
    mean         0.585322
    std          0.281731
    min          0.002004
    25%          0.386770
    50%          0.627140
    75%          0.819888
    max          1.000000
    Name: Percentage, dtype: float64




```python
ax = sns.histplot(tmp, x='Percentage')
quantiles = ['25%','50%','75%']
colors = ['red','orange','green']
for i in range(len(quantiles)):
    a = tmp.Percentage.describe().transpose()[quantiles[i]]
    ax.axvline(a, color=colors[i], label=f'Q{i+1} : {a:.2f}')
plt.xlabel('Percentage')
plt.legend()
plt.title('Distribution of Percentage of Rated Entries in List')
```




    Text(0.5, 1.0, 'Distribution of Percentage of Rated Entries in List')




    
![png](/images/mal_eda/output_105_1.png)
    


Most users have ~39% to 82% of their entire list rated, more than 700 users have not rated any titles on their list, while more than 900 users have rated every title on their list.

<a id='4.2'></a>
### 4.2 Average number of lists a title is added to?


```python
title_all = df.groupby('Anime_Title').count()['Anime_Id'].reset_index()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Anime_Title</th>
      <th>Anime_Id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>"0"</td>
      <td>23</td>
    </tr>
    <tr>
      <th>1</th>
      <td>"Aesop" no Ohanashi yori: Ushi to Kaeru, Yokub...</td>
      <td>7</td>
    </tr>
    <tr>
      <th>2</th>
      <td>"Ai" wo Taberu</td>
      <td>11</td>
    </tr>
    <tr>
      <th>3</th>
      <td>"Bungaku Shoujo" Kyou no Oyatsu: Hatsukoi</td>
      <td>31</td>
    </tr>
    <tr>
      <th>4</th>
      <td>"Bungaku Shoujo" Memoire</td>
      <td>185</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>17360</th>
      <td>Üks Uks</td>
      <td>1</td>
    </tr>
    <tr>
      <th>17361</th>
      <td>ēlDLIVE</td>
      <td>488</td>
    </tr>
    <tr>
      <th>17362</th>
      <td>​Itsudemo Hohoemi wo</td>
      <td>1</td>
    </tr>
    <tr>
      <th>17363</th>
      <td>‎Honekko Parade</td>
      <td>5</td>
    </tr>
    <tr>
      <th>17364</th>
      <td>◯</td>
      <td>56</td>
    </tr>
  </tbody>
</table>
<p>17365 rows × 2 columns</p>
</div>




```python
ax = sns.histplot(title_all, x='Anime_Id', log_scale=True)
quantiles = ['25%','50%','75%']
colors = ['red','orange','green']
for i in range(len(quantiles)):
    a = title_all.Anime_Id.describe().transpose()[quantiles[i]]
    ax.axvline(a, color=colors[i], label=f'Q{i+1} : {a:.2f}')
ax.set(xlabel='Number of Lists Containing Each Unique Title')
plt.legend()
plt.title('Distribution of Percentage of Titles Rated in List')
```




    Text(0.5, 1.0, 'Distribution of Percentage of Titles Rated in List')




    
![png](/images/mal_eda/output_108_1.png)
    


Most titles are added to between 4 and 130 user lists, out of around 17000 unique users we have in the dataset.


```python
title_rated = df[df.Rating_Score != 0].groupby('Anime_Title').count()[['Anime_Id']].reset_index()
```


```python
title_all = df.groupby('Anime_Title').count()['Anime_Id'].reset_index()
```


```python
tmp = title_rated.merge(title_all, how = 'left', on ='Anime_Title')
tmp['Percentage'] = tmp['Anime_Id_x']/tmp['Anime_Id_y']
tmp
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Anime_Title</th>
      <th>Anime_Id_x</th>
      <th>Anime_Id_y</th>
      <th>Percentage</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>"0"</td>
      <td>17</td>
      <td>23</td>
      <td>0.739130</td>
    </tr>
    <tr>
      <th>1</th>
      <td>"Ai" wo Taberu</td>
      <td>6</td>
      <td>11</td>
      <td>0.545455</td>
    </tr>
    <tr>
      <th>2</th>
      <td>"Bungaku Shoujo" Kyou no Oyatsu: Hatsukoi</td>
      <td>20</td>
      <td>31</td>
      <td>0.645161</td>
    </tr>
    <tr>
      <th>3</th>
      <td>"Bungaku Shoujo" Memoire</td>
      <td>116</td>
      <td>185</td>
      <td>0.627027</td>
    </tr>
    <tr>
      <th>4</th>
      <td>"Bungaku Shoujo" Movie</td>
      <td>185</td>
      <td>300</td>
      <td>0.616667</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>14908</th>
      <td>xxxHOLiC Shunmuki</td>
      <td>16</td>
      <td>65</td>
      <td>0.246154</td>
    </tr>
    <tr>
      <th>14909</th>
      <td>xxxHOLiC◆Kei</td>
      <td>43</td>
      <td>146</td>
      <td>0.294521</td>
    </tr>
    <tr>
      <th>14910</th>
      <td>ēlDLIVE</td>
      <td>219</td>
      <td>488</td>
      <td>0.448770</td>
    </tr>
    <tr>
      <th>14911</th>
      <td>‎Honekko Parade</td>
      <td>2</td>
      <td>5</td>
      <td>0.400000</td>
    </tr>
    <tr>
      <th>14912</th>
      <td>◯</td>
      <td>42</td>
      <td>56</td>
      <td>0.750000</td>
    </tr>
  </tbody>
</table>
<p>14913 rows × 4 columns</p>
</div>




```python
ax = sns.histplot(tmp, x='Percentage')
quantiles = ['25%','50%','75%']
colors = ['red','orange','green']
for i in range(len(quantiles)):
    a = tmp.Percentage.describe().transpose()[quantiles[i]]
    ax.axvline(a, color=colors[i], label=f'Q{i+1} : {a:.2f}')
plt.legend()
plt.title('Distribution of Percentage of Titles Rated in List')
```




    Text(0.5, 1.0, 'Distribution of Percentage of Titles Rated in List')




    
![png](/images/mal_eda/output_113_1.png)
    


Most titles are rated in 39% to 64% of the lists they are added to. In the plot we see a peak at around 1.0 where 1400 titles have almost 100% rating rate.


```python
tmp[tmp.Percentage > 0.9].sort_values('Anime_Id_y', ascending=False)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Anime_Title</th>
      <th>Anime_Id_x</th>
      <th>Anime_Id_y</th>
      <th>Percentage</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>13241</th>
      <td>Teekyuu 2 Specials</td>
      <td>21</td>
      <td>22</td>
      <td>0.954545</td>
    </tr>
    <tr>
      <th>4844</th>
      <td>Generation of Chaos Next: Chikai no Pendant</td>
      <td>20</td>
      <td>22</td>
      <td>0.909091</td>
    </tr>
    <tr>
      <th>4068</th>
      <td>Encore</td>
      <td>19</td>
      <td>21</td>
      <td>0.904762</td>
    </tr>
    <tr>
      <th>14597</th>
      <td>Youkai Watch Movie 1: Tanjou no Himitsu da Nyan!</td>
      <td>18</td>
      <td>19</td>
      <td>0.947368</td>
    </tr>
    <tr>
      <th>9464</th>
      <td>Mera Mera</td>
      <td>14</td>
      <td>15</td>
      <td>0.933333</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>8248</th>
      <td>Kung Fu Gonglyong Suhodae</td>
      <td>1</td>
      <td>1</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>8257</th>
      <td>Kura Sushi</td>
      <td>1</td>
      <td>1</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>8285</th>
      <td>Kuroi Ame ni Utarete</td>
      <td>1</td>
      <td>1</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>8293</th>
      <td>Kurokan</td>
      <td>1</td>
      <td>1</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>14904</th>
      <td>the FLY BanD!</td>
      <td>1</td>
      <td>1</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
<p>1397 rows × 4 columns</p>
</div>




```python
tmp[(tmp.Percentage > 0.9)&(tmp.Anime_Id_y == 1)]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Anime_Title</th>
      <th>Anime_Id_x</th>
      <th>Anime_Id_y</th>
      <th>Percentage</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>880</th>
      <td>Anime Nihon no Mukashibanashi</td>
      <td>1</td>
      <td>1</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>923</th>
      <td>Annyeong Jadoo: In-eogongju Pyeon</td>
      <td>1</td>
      <td>1</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>974</th>
      <td>Ao Fei Q Chong</td>
      <td>1</td>
      <td>1</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1037</th>
      <td>Appa eolil Jeog-en</td>
      <td>1</td>
      <td>1</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1155</th>
      <td>Arpo The Robot</td>
      <td>1</td>
      <td>1</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>14875</th>
      <td>_Summer Specials</td>
      <td>1</td>
      <td>1</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>14898</th>
      <td>loTus feat. Pt. Ajay Pohankar</td>
      <td>1</td>
      <td>1</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>14902</th>
      <td>s.CRY.ed Alteration I: Tao</td>
      <td>1</td>
      <td>1</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>14903</th>
      <td>s.CRY.ed Alteration II: Quan</td>
      <td>1</td>
      <td>1</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>14904</th>
      <td>the FLY BanD!</td>
      <td>1</td>
      <td>1</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
<p>891 rows × 4 columns</p>
</div>



This observation is due to almost 900 titles having only been added to 1 user list, and that entry is also rated. For the remaining 500 titles they are similarly obscure titles where very few users have added them to their lists, and when they appear on a user list they are usually rated.


```python
tmp[(tmp.Percentage < 0.1)]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Anime_Title</th>
      <th>Anime_Id_x</th>
      <th>Anime_Id_y</th>
      <th>Percentage</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>7</th>
      <td>"Eikou Naki Tensai-tachi" Kara no Monogatari</td>
      <td>1</td>
      <td>12</td>
      <td>0.083333</td>
    </tr>
    <tr>
      <th>14</th>
      <td>"Oshi no Ko" Season 2</td>
      <td>1</td>
      <td>4130</td>
      <td>0.000242</td>
    </tr>
    <tr>
      <th>20</th>
      <td>"Uchuu Senkan Yamato" to Iu Jidai: Seireki 220...</td>
      <td>6</td>
      <td>62</td>
      <td>0.096774</td>
    </tr>
    <tr>
      <th>87</th>
      <td>11-piki no Neko to Ahoudori</td>
      <td>1</td>
      <td>13</td>
      <td>0.076923</td>
    </tr>
    <tr>
      <th>160</th>
      <td>3-nen D-gumi Glass no Kamen: Tobidase! Watashi...</td>
      <td>1</td>
      <td>21</td>
      <td>0.047619</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>14376</th>
      <td>Xiling Jiyuan</td>
      <td>1</td>
      <td>18</td>
      <td>0.055556</td>
    </tr>
    <tr>
      <th>14430</th>
      <td>Yakushiji Ryouko no Kaiki Jikenbo</td>
      <td>1</td>
      <td>13</td>
      <td>0.076923</td>
    </tr>
    <tr>
      <th>14522</th>
      <td>Yichang Shengwu Jianwenlu</td>
      <td>3</td>
      <td>37</td>
      <td>0.081081</td>
    </tr>
    <tr>
      <th>14816</th>
      <td>Zettai Karen Children</td>
      <td>3</td>
      <td>33</td>
      <td>0.090909</td>
    </tr>
    <tr>
      <th>14870</th>
      <td>Zuoshou Shanglan</td>
      <td>2</td>
      <td>47</td>
      <td>0.042553</td>
    </tr>
  </tbody>
</table>
<p>139 rows × 4 columns</p>
</div>




```python
tmp[(tmp.Percentage < 0.1)&(tmp.Anime_Id_y > 1000)].sort_values('Anime_Id_y', ascending=False)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Anime_Title</th>
      <th>Anime_Id_x</th>
      <th>Anime_Id_y</th>
      <th>Percentage</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>8077</th>
      <td>Kono Subarashii Sekai ni Shukufuku wo! 3</td>
      <td>369</td>
      <td>4843</td>
      <td>0.076192</td>
    </tr>
    <tr>
      <th>7716</th>
      <td>Kimetsu no Yaiba: Hashira Geiko-hen</td>
      <td>58</td>
      <td>4370</td>
      <td>0.013272</td>
    </tr>
    <tr>
      <th>14</th>
      <td>"Oshi no Ko" Season 2</td>
      <td>1</td>
      <td>4130</td>
      <td>0.000242</td>
    </tr>
    <tr>
      <th>9877</th>
      <td>Mushoku Tensei II: Isekai Ittara Honki Dasu Pa...</td>
      <td>397</td>
      <td>4056</td>
      <td>0.097880</td>
    </tr>
    <tr>
      <th>2008</th>
      <td>Boku no Hero Academia 7th Season</td>
      <td>5</td>
      <td>3659</td>
      <td>0.001366</td>
    </tr>
    <tr>
      <th>7144</th>
      <td>Kaijuu 8-gou</td>
      <td>2</td>
      <td>2862</td>
      <td>0.000699</td>
    </tr>
    <tr>
      <th>13357</th>
      <td>Tensei shitara Slime Datta Ken 3rd Season</td>
      <td>241</td>
      <td>2719</td>
      <td>0.088636</td>
    </tr>
    <tr>
      <th>10572</th>
      <td>One Punch Man 3</td>
      <td>1</td>
      <td>2638</td>
      <td>0.000379</td>
    </tr>
    <tr>
      <th>11483</th>
      <td>Re:Zero kara Hajimeru Isekai Seikatsu 3rd Season</td>
      <td>1</td>
      <td>2104</td>
      <td>0.000475</td>
    </tr>
    <tr>
      <th>3336</th>
      <td>Date A Live V</td>
      <td>149</td>
      <td>1961</td>
      <td>0.075982</td>
    </tr>
    <tr>
      <th>5396</th>
      <td>Haikyuu!! Movie: Gomisuteba no Kessen</td>
      <td>20</td>
      <td>1768</td>
      <td>0.011312</td>
    </tr>
    <tr>
      <th>9001</th>
      <td>Mahouka Koukou no Rettousei 3rd Season</td>
      <td>107</td>
      <td>1342</td>
      <td>0.079732</td>
    </tr>
    <tr>
      <th>12860</th>
      <td>Spy x Family Movie: Code: White</td>
      <td>93</td>
      <td>1300</td>
      <td>0.071538</td>
    </tr>
    <tr>
      <th>4199</th>
      <td>Fairy Tail: 100 Years Quest</td>
      <td>1</td>
      <td>1295</td>
      <td>0.000772</td>
    </tr>
    <tr>
      <th>10683</th>
      <td>Ore dake Level Up na Ken Season 2: Arise from ...</td>
      <td>1</td>
      <td>1182</td>
      <td>0.000846</td>
    </tr>
    <tr>
      <th>12018</th>
      <td>Seishun Buta Yarou wa Randoseru Girl no Yume w...</td>
      <td>82</td>
      <td>1153</td>
      <td>0.071119</td>
    </tr>
    <tr>
      <th>8332</th>
      <td>Kusuriya no Hitorigoto 2nd Season</td>
      <td>1</td>
      <td>1118</td>
      <td>0.000894</td>
    </tr>
    <tr>
      <th>7140</th>
      <td>Kaii to Otome to Kamikakushi</td>
      <td>104</td>
      <td>1061</td>
      <td>0.098021</td>
    </tr>
  </tbody>
</table>
</div>



At the other end of the spectrum we see a low number of titles with less <0.1 on the plot. Most of these titles appear to be highly anticipated titles that are currently airing or recently released, where users have not managed to complete and rate them.

<a id='4.3'></a>
### 4.3 Is this dataset representative of the population data?
As our user data contains ratings from a subset of the total user population on the site, we want to check if our data is representative of the site's rating data.


```python
ax = sns.histplot(df[df.Rating_Score!=0].groupby('Anime_Title')[['Rating_Score']].mean(), x='Rating_Score')
quantiles = ['25%','50%','75%']
colors = ['red','orange','green']
for i in range(len(quantiles)):
    a = df[df.Rating_Score!=0].groupby('Anime_Title')[['Rating_Score']].mean().describe().transpose()[quantiles[i]]['Rating_Score']
    ax.axvline(a, color=colors[i], label=f'Q{i+1} : {a:.2f}')
plt.legend()
plt.title('Distribution of Average Title Scores')
```




    Text(0.5, 1.0, 'Distribution of Average Title Scores')




    
![png](/images/mal_eda/output_121_1.png)
    


Looking at the distribution of average title scores from our user ratings data, most average scores fall between 5.27 to 7.29. This is fairly close to the site average of 5.83 to 7.21 that we saw previously.

In this distribution we see peaks at every whole number due to obscure titles being added to very few (or a single) list and ending up with a whole number for its average score.

We can also compare the distributions with a student t test to get a more quantitative result.


```python
cleaned_df['Score'].describe()
```




    count    13300.000000
    mean         6.456092
    std          1.027267
    min          1.869653
    25%          5.827480
    50%          6.548627
    75%          7.205349
    max          9.276142
    Name: Score, dtype: float64




```python
df[df.Rating_Score!=0].groupby('Anime_Title')['Rating_Score'].mean().describe()
```




    count    14913.000000
    mean         6.403362
    std          1.402710
    min          1.000000
    25%          5.723404
    50%          6.593750
    75%          7.291667
    max         10.000000
    Name: Rating_Score, dtype: float64




```python
scipy.stats.ttest_ind(cleaned_df['Score'].values, df[df.Rating_Score!=0].groupby('Anime_Title')['Rating_Score'].mean().values)
```




    TtestResult(statistic=3.565581711830044, pvalue=0.0003636502206012928, df=28211.0)




```python
sm.stats.weightstats.ztest(cleaned_df['Score'].values, df[df.Rating_Score!=0].groupby('Anime_Title')['Rating_Score'].mean().values)
```




    (3.565581711830044, 0.0003630500223969563)



We see T statistics of 3.56 and p << 0.05, suggesting that the actual population mean is higher than our sample mean. Hence our sample mean is not representative of the population mean.

Some possible reasons as why this might have happened:
1. User data was scraped using from users who were active at the time of scraping. If user behaviour when rating titles has changed from the past our sample data will not be able to show these changes. However the data will still be considered in the population mean
2. Insufficient samples were scraped, evident from the peaks at the whole numbers. Additional user ratings may need to be scraped to obtain more samples for more obscure titles.

<a id='5'></a>
## 5. Conclusion
In this notebook we have explored the dataset that were scraped from the community site, drawing insights on content attributes, industry behaviour, and user behaviour such as the average user uses only the 4-10 ratings on the 1-10 scale provided.

Some limitations of the data was also identified, most notably the webscraping max limits placed on reviews per title and titles per userlist resulting in incomplete data. The user rating data was also found to not be representative of the site's average ratings, possibly due to insufficient data collected.

This exploration has provided some insight and intuition around these datasets, allowing us to continue with creating models from these datasets now that we have a better understanding on the data available.
